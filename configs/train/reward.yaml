algorithm: reward

data:
  train_path: data/repliqa/clean/train.jsonl
  eval_path: data/repliqa/clean/eval.jsonl
  documents_path: data/repliqa/clean/documents.jsonl

prompt:
  template: |
    You are a question answering assistant.

    Answer the question ONLY using the provided document.

    If the answer cannot be found in the document, say:
    FINAL: Not found

    Keep the answer concise. Do not provide explanation.

    Format your response exactly as:

    FINAL: <short answer>

    Document:
    {context}

    Question:
    {question}

reward_data:
  train_path: data/repliqa/clean/reward_train.jsonl
  eval_path: data/repliqa/clean/reward_eval.jsonl
  force_rebuild: false

training:
  output_dir: runs/reward_qwen05b
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  num_train_epochs: 1
  learning_rate: 5e-6
  max_length: 1024
  logging_steps: 10
  eval_strategy: steps
  eval_steps: 200
  save_steps: 200
  gradient_checkpointing: true
  dataset_num_proc: 1
  center_rewards_coefficient: 0.0
  report_to: none
  merge_lora_on_save: true

model:
  model_name: Qwen/Qwen2.5-0.5B-Instruct
  use_lora: true

lora:
  r: 16
  alpha: 32
  dropout: 0.05
  target_modules:
    - q_proj
    - v_proj
